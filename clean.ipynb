{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATAML 2024-25: Pulse Shape Discrimination\n",
        "\n",
        "**Objective**  \n",
        "This project focuses on the discrimination between two types of scintillation signals, **Li6** and **Po**, and how the resulting model (or models) can be applied to a third, unlabeled dataset **Phys**.\n",
        "\n",
        "Below, we walk through:\n",
        "1. **Dataset Exploration**: Understanding waveform differences, preliminary statistics, and basic comparisons.\n",
        "2. **Feature-Based Classification**: Basic ML classifiers (RandomForest, SVM, XGBoost).\n",
        "3. **CNN-Based Approaches**: Single-branch, multi-branch, and attention-based architectures for deeper insight.\n",
        "4. **Model Uncertainty & Contamination Control**: Ensuring that Po contamination remains at or below 5%.\n",
        "5. **Classifying Phys**: Predicting the class labels (Li6 vs. Po) for an unlabeled real-world dataset.\n",
        "\n",
        "In response to the **Project Tasks**, additional Markdown explanations and in-code comments have been provided to elucidate each step, methodology, and rationale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Exploration\n",
        "\n",
        "### Motivation\n",
        "We begin by **qualitatively** exploring and visualizing the Li6 and Po datasets. This serves to reveal:\n",
        "- Initial differences in shape, amplitude, frequency components, etc.\n",
        "- Key features that might provide robust discrimination (mean amplitude, maximum amplitude, frequency domain patterns, etc.).\n",
        "\n",
        "### Format of Input Data\n",
        "Each signal is stored as a multi-dimensional array of shape `(N, 4, T)`, where:\n",
        "- **N** = number of samples in the dataset\n",
        "- **4** = number of detector channels\n",
        "- **T** = number of timepoints per waveform (e.g., 2000 or truncated)\n",
        "\n",
        "These waveforms are used both for **feature-based** ML approaches and for **deep learning** (CNNs, attention). Truncation or fraction sampling is often applied to reduce computational load.\n",
        "\n",
        "### PyTorch Dataset & Splitting\n",
        "For downstream tasks, we build a custom **PyTorch Dataset** (see `ScintillationDataset`) that returns `(waveform, label)` pairs. A typical 80/20 train-test split is used to ensure a robust evaluation while retaining sufficient training data. In some cases, we sample only a fraction of the dataset due to memory or time constraints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Libraries and Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Data loading & feature extraction utilities\n",
        "from utils.data_loading import load_waveforms\n",
        "from utils.features_extraction import extract_features_dataset\n",
        "\n",
        "# Waveform analysis (stats & waveforms)\n",
        "from utils.waveforms_analysis import (\n",
        "    compute_statistics,\n",
        "    plot_stat_distributions,\n",
        "    compute_average_waveform,\n",
        "    plot_overall_average_overlay,\n",
        "    plot_random_waveforms,\n",
        "    plot_average_waveforms_per_detector,\n",
        "    plot_difference_waveforms_per_detector,\n",
        "    plot_heatmap_avg_difference\n",
        ")\n",
        "\n",
        "# Features visualization\n",
        "from utils.features_visualization import (\n",
        "    plot_features_by_base_feature\n",
        ")\n",
        "\n",
        "# Machine Learning utilities\n",
        "from utils.ml_classifiers import create_dataset, train_and_evaluate_ml\n",
        "# Deep Learning utilities\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from utils.deep_learning import (\n",
        "    TwoDConvNet,\n",
        "    train_one_epoch,\n",
        "    evaluate,\n",
        "    ScintillationDataset,\n",
        "    TwoDConvNetWithFullAttention,\n",
        "    MultiBranchCNN,\n",
        "    train_and_evaluate\n",
        ")\n",
        "\n",
        "# Uncertainty estimation utilities\n",
        "from utils.uncertainty import (\n",
        "    mc_dropout_predict,\n",
        "    plot_uncertainty_distribution,\n",
        "    plot_sample_prediction\n",
        ")\n",
        "\n",
        "# Analysis utilities\n",
        "from utils.analysis import (\n",
        "    find_threshold_for_contamination,\n",
        "    classify_dataset\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. Loading the Data\n",
        "\n",
        "We begin by loading a small fraction (1%) of each dataset for rapid testing and memory savings. \n",
        "Here, we specify `time_start=200` and `time_end=2000`, which effectively **truncates** the waveform\n",
        "to focus on the most relevant region (often the region where the scintillation event is dominant)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explanation: We load Li6 and Po waveforms using our helper function \"load_waveforms\".\n",
        "# Note that \"fraction=0.01\" uses only 10% of the entire dataset for quick iteration.\n",
        "\n",
        "Li6_waveforms = load_waveforms(\"data/Li6.npz\", key=\"data_array\", fraction=0.1, time_start=0, time_end=7756)\n",
        "Po_waveforms = load_waveforms(\"data/Po.npz\", key=\"data_array\", fraction=0.1, time_start=0, time_end=7756)\n",
        "\n",
        "print(f\"Li6 shape: {Li6_waveforms.shape}, Po shape: {Po_waveforms.shape}\")\n",
        "print(f\"Li6 dataset shape: {Li6_waveforms.shape} (samples, channels, timepoints)\")\n",
        "print(f\"Po dataset shape: {Po_waveforms.shape} (samples, channels, timepoints)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Random Waveform Visualization\n",
        "\n",
        "Plotting random waveforms provides a **qualitative** look at amplitude levels, noise characteristics, and general shape. This helps us form an intuition about how Li6 and Po differ in their time-domain behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_random_waveforms(Li6_waveforms, dataset_name=\"Li6\", num_samples=1)\n",
        "plot_random_waveforms(Po_waveforms, dataset_name=\"Po\", num_samples=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3. Basic Statistics\n",
        "\n",
        "We compute distributions of **mean** and **max** amplitudes for both Li6 and Po. Such global statistics often reveal fundamental distinctions in event amplitude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explanation: compute_statistics returns basic stats like mean and max per sample.\n",
        "Li6_stats = compute_statistics(Li6_waveforms)\n",
        "Po_stats = compute_statistics(Po_waveforms)\n",
        "\n",
        "# Plot distributions of Mean Amplitude\n",
        "plot_stat_distributions(\n",
        "    Li6_stats[\"mean\"], Po_stats[\"mean\"],\n",
        "    stat_name=\"Mean Amplitude\", dataset_names=(\"Li6\", \"Po\")\n",
        ")\n",
        "\n",
        "# Plot distributions of Max Amplitude\n",
        "plot_stat_distributions(\n",
        "    Li6_stats[\"max\"], Po_stats[\"max\"],\n",
        "    stat_name=\"Max Amplitude\", dataset_names=(\"Li6\", \"Po\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4. Average Waveform Comparison\n",
        "\n",
        "We visualize the **average** waveform per channel for Li6 and Po, and then examine the difference. \n",
        "This highlights which time segments or channels may exhibit the largest dissimilarities between classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explanation: We aggregate waveforms sample-wise to compute channel-wise average signals for Li6 and Po.\n",
        "avg_Li6 = compute_average_waveform(Li6_waveforms)\n",
        "avg_Po = compute_average_waveform(Po_waveforms)\n",
        "\n",
        "# Plot average waveforms per detector\n",
        "plot_average_waveforms_per_detector(avg_Li6, avg_Po)\n",
        "\n",
        "# Plot differences in average waveforms per detector\n",
        "plot_difference_waveforms_per_detector(avg_Li6, avg_Po)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we create a **2D histogram** to visualize the time vs. amplitude difference across channels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_heatmap_avg_difference(avg_Li6, avg_Po)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5. Focused Analysis on Initial Time Indices\n",
        "\n",
        "Often, the primary discrimination power lies in the **initial** part of the waveform. Below, we truncate the first 800 time samples and replicate our visual analyses. This can reveal more pronounced differences if noise or baseline variations occur later in time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_focus_start = 0\n",
        "time_focus_end = 800\n",
        "\n",
        "avg_Li6_focus = avg_Li6[:, time_focus_start:time_focus_end]\n",
        "avg_Po_focus = avg_Po[:, time_focus_start:time_focus_end]\n",
        "\n",
        "plot_average_waveforms_per_detector(avg_Li6_focus, avg_Po_focus)\n",
        "plot_difference_waveforms_per_detector(avg_Li6_focus, avg_Po_focus)\n",
        "\n",
        "plot_heatmap_avg_difference(avg_Li6_focus, avg_Po_focus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Extraction\n",
        "\n",
        "We extract features capturing both time and frequency domain characteristics:\n",
        "- **Mean**: Average amplitude over time.\n",
        "- **Peak**: Maximum amplitude.\n",
        "- **Dominant Frequency**: Main frequency peak in the spectrum.\n",
        "- **Spectral Entropy**: Measures the distribution of spectral energy.\n",
        "\n",
        "Each channel (4 total) contributes these 4 features, leading to 16 dimensions per sample. We then visualize these distributions across Li6 vs. Po."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_names = [\"Mean\", \"Peak\", \"Dominant_Freq\", \"Spectral_Entropy\"]\n",
        "feature_names_full = [f\"{name}_Ch{i}\" for i in range(4) for name in feature_names]\n",
        "\n",
        "# Example assumption: real sampling rate is 1 MHz\n",
        "Li6_features = extract_features_dataset(Li6_waveforms, sampling_rate=1000000.0)\n",
        "Po_features  = extract_features_dataset(Po_waveforms, sampling_rate=1000000.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Compare Extracted Features by Base Feature\n",
        "\n",
        "We produce histograms of each **base feature** across all four channels, overlaying Li6 vs Po. \n",
        "This allows for a channel-specific analysis, e.g., how does the mean amplitude in channel 2 compare between Li6 and Po?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_features = [\"Mean\", \"Peak\", \"Dominant_Freq\", \"Spectral_Entropy\"]\n",
        "\n",
        "plot_features_by_base_feature(\n",
        "    features_Li6=Li6_features,\n",
        "    features_Po=Po_features,\n",
        "    base_feature_names=base_features,\n",
        "    save_path=\"plots/features_by_base_feature\",\n",
        "    show=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Detailed Pair Plot of Selected Features\n",
        "\n",
        "To visualize **joint distributions**, we pick 4 representative features: \n",
        "- **Mean_Ch0**, **Peak_Ch1**, **Spectral_Entropy_Ch2**, **Mean_Ch3** \n",
        "and plot a Seaborn Pair Plot. \n",
        "\n",
        "This helps confirm or reject correlations that might be used for discrimination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_features = [\"Mean_Ch0\", \"Peak_Ch1\", \"Spectral_Entropy_Ch2\", \"Mean_Ch3\"]\n",
        "print(f\"Selected Features for Pair Plot: {selected_features}\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Determine indices corresponding to selected features\n",
        "selected_indices = []\n",
        "for feat in selected_features:\n",
        "    if feat in feature_names_full:\n",
        "        selected_indices.append(feature_names_full.index(feat))\n",
        "    else:\n",
        "        print(f\"Warning: feature '{feat}' not found in 'feature_names_full'.\")\n",
        "\n",
        "# Combine Li6 and Po features\n",
        "features = np.vstack([Li6_features, Po_features])\n",
        "labels = np.concatenate([\n",
        "    np.zeros(len(Li6_features), dtype=int),\n",
        "    np.ones(len(Po_features), dtype=int)\n",
        "])\n",
        "\n",
        "# Subset the columns from 'features'\n",
        "subset_features = features[:, selected_indices]\n",
        "\n",
        "# Create a DataFrame for Seaborn\n",
        "df_subset = pd.DataFrame(subset_features, columns=selected_features)\n",
        "df_subset[\"Label\"] = [\"Li6\" if lab == 0 else \"Po\" for lab in labels]\n",
        "\n",
        "print(f\"Shape of the pair-plot DataFrame: {df_subset.shape}\")\n",
        "print(df_subset.head())\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "pair_plot = sns.pairplot(\n",
        "    data=df_subset, \n",
        "    hue=\"Label\",\n",
        "    diag_kind=\"kde\",\n",
        "    corner=True,\n",
        "    palette=[\"blue\", \"red\"]\n",
        ")\n",
        "\n",
        "pair_plot.fig.suptitle(\"Pair Plot of Selected Features (Li6 vs Po)\", y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Building a Simple Classifier\n",
        "\n",
        "**Motivation**: We start with simpler classifiers (RandomForest, SVM, XGBoost) as baselines before proceeding to more complex neural architectures.\n",
        "\n",
        "- **Goal**: Achieve at least 80% accuracy in discriminating Li6 vs Po.\n",
        "- **Metrics**: We log accuracy, confusion matrix, classification report, etc.\n",
        "- **Stopping Criterion**: For these simpler models, we rely on standard model training or built-in solvers (e.g., XGBoost’s iteration limit). Early stopping can be used if overfitting is detected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explanation: The function create_dataset merges Li6 & Po features -> (X, y).\n",
        "use_fusion = False  # If True, uses 'extract_features_fusion'; otherwise uses simpler approach.\n",
        "\n",
        "X, y = create_dataset(\n",
        "    Li6_data=Li6_waveforms,\n",
        "    Po_data=Po_waveforms,\n",
        "    fusion=use_fusion\n",
        ")\n",
        "print(\"Dataset shapes:\")\n",
        "print(\"X:\", X.shape, \"  y:\", y.shape)\n",
        "print(\"First row of X:\", X[0])\n",
        "print(\"First label:\", y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1. Train-Test Split + Normalization\n",
        "We allocate 80% for training, 20% for testing, and standardize the features with `StandardScaler`. \n",
        "This helps many classifiers (like SVM) by giving each feature zero mean, unit variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, \n",
        "    y, \n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")\n",
        "print(f\"Train set size: {X_train.shape}, Test set size: {X_test.shape}\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "print(\"Example scaled training row:\", X_train_scaled[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2. Model Selection and Training\n",
        "\n",
        "We loop through three model types: \n",
        "- **Random Forest (rf)** \n",
        "- **Support Vector Machine (svm)** \n",
        "- **XGBoost (xgb)**  \n",
        "\n",
        "We measure performance on the test set after training, visualizing a **probability histogram**, **confusion matrix**, and **classification report**. We also log final test accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_types = [\"rf\", \"svm\", \"xgb\"]  # \"RandomForest\", \"SVM\", and \"XGBoost\"\n",
        "threshold = 0.5                    # Probability threshold for classification\n",
        "\n",
        "results_summary = {}\n",
        "\n",
        "for m_type in model_types:\n",
        "    print(\"======================================================\")\n",
        "    print(f\"TRAINING MODEL: {m_type.upper()}\")\n",
        "    print(\"======================================================\")\n",
        "\n",
        "    trained_model, y_pred_proba = train_and_evaluate_ml(\n",
        "        X_train_scaled,\n",
        "        X_test_scaled,\n",
        "        y_train,\n",
        "        y_test,\n",
        "        model_type=m_type,\n",
        "        threshold=threshold\n",
        "    )\n",
        "    \n",
        "    # Convert probabilities -> predicted labels\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results_summary[m_type] = acc\n",
        "\n",
        "print(\"\\nSUMMARY OF ACCURACIES:\")\n",
        "for k, v in results_summary.items():\n",
        "    print(f\"Model {k.upper()} => Accuracy = {v:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Deep Learning Approaches\n",
        "\n",
        "**Motivation**: CNNs and Attention can exploit the temporal structure of the waveforms more directly than feature-engineering alone.\n",
        "\n",
        "In the code below, we illustrate:\n",
        "1. **Single-Branch 2D CNN**: Treats `(4,time)` as a 2D “image.”\n",
        "2. **Multi-Branch CNN**: Each channel is processed by its own 1D CNN branch, then concatenated.\n",
        "3. **CNN + Attention**: Incorporates a self-attention mechanism to highlight the most relevant time segments.\n",
        "\n",
        "**Loss & Accuracy** are recorded at each epoch. We generally train for a fixed number of epochs (e.g. 10) and would apply **early stopping** if the validation loss fails to improve (not shown here, but recommended in practice)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1. Data Preparation for CNN\n",
        "\n",
        "We load Li6 and Po waveforms again (optionally truncated), label them, and create a **ScintillationDataset** for PyTorch. \n",
        "We then do an 80/20 split and build DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Li6 shape= (10600, 4, 7756) Po shape= (10447, 4, 7756)\n"
          ]
        }
      ],
      "source": [
        "li6_data = load_waveforms(\"data/Li6.npz\", key=\"data_array\", fraction=0.2, time_start=0, time_end=7756)\n",
        "po_data  = load_waveforms(\"data/Po.npz\",  key=\"data_array\", fraction=0.2, time_start=0, time_end=7756)\n",
        "time_span = 7756\n",
        "print(\"Li6 shape=\", li6_data.shape, \"Po shape=\", po_data.shape)\n",
        "\n",
        "li6_labels = np.zeros(len(li6_data), dtype=np.int64)\n",
        "po_labels  = np.ones(len(po_data),  dtype=np.int64)\n",
        "\n",
        "# Explanation: We combine the Li6 & Po waveforms, but for deep learning below,\n",
        "# we typically rely on the custom 'ScintillationDataset' rather than a single array.\n",
        "full_data   = np.concatenate([li6_data, po_data], axis=0)\n",
        "full_labels = np.concatenate([li6_labels, po_labels], axis=0)\n",
        "\n",
        "# Build PyTorch dataset => returns (waveform, label)\n",
        "dataset = ScintillationDataset(li6_data, po_data)\n",
        "\n",
        "ds_size     = len(dataset)\n",
        "train_size  = int(0.8 * ds_size)\n",
        "test_size   = ds_size - train_size\n",
        "train_ds, test_ds = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2. Single-Branch 2D CNN\n",
        "\n",
        "We define a simple 2D CNN (see `TwoDConvNet`) that treats each sample as `(1, 4, width)`. \n",
        "We train for 10 epochs and evaluate test accuracy/loss.\n",
        "\n",
        "**Note**: In real experiments, you would:\n",
        " - Possibly train longer or apply early stopping\n",
        " - Tune batch size, learning rate, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn = TwoDConvNet(num_classes=2, width=time_span)\n",
        "\n",
        "trained_model_cnn, metrics_cnn = train_and_evaluate(\n",
        "    model=model_cnn,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    num_epochs=10,\n",
        "    learning_rate=1e-3,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "torch.save(trained_model_cnn.state_dict(), \"models/trained_model_cnn.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3. Multi-Branch CNN\n",
        "\n",
        "Each of the 4 channels is processed independently in separate 1D CNN branches, preserving each detector’s unique characteristics. The outputs are concatenated and fed into a classification head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_mb = MultiBranchCNN(input_length=time_span, num_classes=2)\n",
        "\n",
        "trained_model_mb, metrics_mb = train_and_evaluate(\n",
        "    model=model_mb,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    num_epochs=10,\n",
        "    learning_rate=1e-3,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "torch.save(trained_model_cnn.state_dict(), \"models/trained_model_mb.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4. CNN + Attention\n",
        "\n",
        "We incorporate **self-attention** to learn a weighting over the temporal dimension, focusing on the most relevant segments. \n",
        "This is especially beneficial if only certain time intervals contain discriminative signal features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_attn = TwoDConvNetWithFullAttention(num_classes=2, feature_size=64)\n",
        "\n",
        "trained_model_attn, metrics_attn = train_and_evaluate(\n",
        "    model=model_attn,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    num_epochs=10,\n",
        "    learning_rate=1e-3,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "torch.save(trained_model_cnn.state_dict(), \"models/trained_model_attn.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Epistemic Uncertainty Estimation\n",
        "\n",
        "**Motivation**: We seek to understand when the model is “unsure,” especially crucial in physics applications. \n",
        "\n",
        "**Chosen Method**: **Monte Carlo Dropout** (Gal & Ghahramani, 2016)  \n",
        "By enabling dropout at inference and performing multiple stochastic forward passes, we obtain a distribution of predicted probabilities.\n",
        "\n",
        "- **Mean**: Central predicted probability for Li6 (or Po).  \n",
        "- **Standard Deviation**: Confidence or uncertainty measure.  \n",
        "\n",
        "This helps identify ambiguous signals and refine our contamination thresholds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\André\\AppData\\Local\\Temp\\ipykernel_12308\\984705833.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict_attn = torch.load(\"models/trained_model_attn.pth\", map_location=torch.device(device))\n",
            "C:\\Users\\André\\AppData\\Local\\Temp\\ipykernel_12308\\984705833.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict_cnn = torch.load(\"models/trained_model_cnn.pth\", map_location=torch.device(device))  # Fixed filename\n",
            "C:\\Users\\André\\AppData\\Local\\Temp\\ipykernel_12308\\984705833.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict_mb = torch.load(\"models/trained_model_mb.pth\", map_location=torch.device(device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Load state dictionaries from files\n",
        "state_dict_attn = torch.load(\"models/trained_model_attn.pth\", map_location=torch.device(device))\n",
        "state_dict_cnn = torch.load(\"models/trained_model_cnn.pth\", map_location=torch.device(device))  # Fixed filename\n",
        "state_dict_mb = torch.load(\"models/trained_model_mb.pth\", map_location=torch.device(device))\n",
        "\n",
        "# Remove \"module.\" prefix if the model was saved using DataParallel\n",
        "state_dict_attn = {k.replace(\"module.\", \"\"): v for k, v in state_dict_attn.items()}\n",
        "state_dict_cnn = {k.replace(\"module.\", \"\"): v for k, v in state_dict_cnn.items()}\n",
        "state_dict_mb = {k.replace(\"module.\", \"\"): v for k, v in state_dict_mb.items()}\n",
        "\n",
        "# Load state dictionaries into respective models\n",
        "trained_model_attn = TwoDConvNetWithFullAttention(num_classes=2, feature_size=64)\n",
        "trained_model_cnn = TwoDConvNet(num_classes=2, width=time_span)\n",
        "trained_model_mb = MultiBranchCNN(input_length=time_span, num_classes=2)\n",
        "\n",
        "trained_model_attn.load_state_dict(state_dict_attn)\n",
        "trained_model_cnn.load_state_dict(state_dict_cnn)\n",
        "trained_model_mb.load_state_dict(state_dict_mb)\n",
        "\n",
        "print(\"Models loaded successfully.\")\n",
        "\n",
        "# Ensure all models are on the same device as inputs\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "trained_model_attn = trained_model_attn.to(device)\n",
        "trained_model_cnn = trained_model_cnn.to(device)\n",
        "trained_model_mb = trained_model_mb.to(device)\n",
        "\n",
        "# Ensure models are in evaluation mode\n",
        "trained_model_attn.eval()\n",
        "trained_model_cnn.eval()\n",
        "trained_model_mb.eval()\n",
        "\n",
        "# Prepare models for evaluation\n",
        "models = [\n",
        "    (trained_model_attn, \"CNN+Attention\"),\n",
        "    (trained_model_cnn,  \"Single-Branch CNN\"),\n",
        "    (trained_model_mb,   \"Multi-Branch CNN\")\n",
        "]\n",
        "\n",
        "# Perform predictions with MC Dropout\n",
        "for model, model_name in models:\n",
        "    predictions_mean, predictions_std, true_labels = mc_dropout_predict(\n",
        "        model=model,\n",
        "        dataloader=test_loader,\n",
        "        device=device,  # Ensure the model and data loader use the same device\n",
        "        num_forward_passes=30\n",
        "    )\n",
        "\n",
        "    # Plot the overall distribution of standard deviations\n",
        "    plot_uncertainty_distribution(\n",
        "        predictions_mean, \n",
        "        predictions_std, \n",
        "        bins=40,\n",
        "        title=f\"{model_name}: Uncertainty Distribution\"\n",
        "    )\n",
        "\n",
        "    # Inspect an example sample's predictive distribution\n",
        "    sample_to_check = 10\n",
        "    plot_sample_prediction(\n",
        "        predictions_mean, \n",
        "        predictions_std, \n",
        "        sample_idx=sample_to_check, \n",
        "        class_names=[\"Li6\", \"Po\"]\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Limit Po Contamination to 5%\n",
        "\n",
        "In many real-world scenarios, we have a **hard limit** on Po contamination. We choose a probability threshold on **p(Li6)** that ensures only 5% of actual Po signals are misclassified as Li6.\n",
        "\n",
        "This approach might reduce total Li6 recall, but maintains the contamination requirement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "thresholds = {}\n",
        "\n",
        "models = [\n",
        "    (trained_model_cnn,  \"Single-Branch CNN\"),\n",
        "    (trained_model_mb,   \"Multi-Branch CNN\"),\n",
        "    (trained_model_attn, \"CNN+Attention\")\n",
        "]\n",
        "\n",
        "# Explanation: \"mc_dropout_predict\" can be used for single pass as well (num_forward_passes=1).\n",
        "# We then pass these predicted Li6 probabilities to a function that solves for the threshold that yields max_po_contamination <= 5%.\n",
        "\n",
        "for model, name in models:\n",
        "    predictions_mean, _, true_labels = mc_dropout_predict(\n",
        "        model=model,\n",
        "        dataloader=test_loader,     \n",
        "        device=device,\n",
        "        num_forward_passes=1        \n",
        "    )\n",
        "\n",
        "    p_li6 = predictions_mean[:, 0]\n",
        "    max_po_contamination = 0.05\n",
        "    threshold = find_threshold_for_contamination(\n",
        "        probabilities_li6=p_li6,\n",
        "        labels=true_labels,         # 0=Li6, 1=Po\n",
        "        max_po_contamination=max_po_contamination\n",
        "    )\n",
        "\n",
        "    if threshold is None:\n",
        "        print(f\"{name}: Could NOT find threshold for 5% contamination.\")\n",
        "        threshold = 0.5\n",
        "    else:\n",
        "        print(f\"{name}: threshold for 5% contamination = {threshold:.3f}\")\n",
        "\n",
        "    thresholds[name] = threshold\n",
        "\n",
        "    predicted_labels = np.where(p_li6 > threshold, 0, 1)  # 0=Li6, 1=Po\n",
        "\n",
        "    li6_mask = (true_labels == 0)\n",
        "    po_mask  = (true_labels == 1)\n",
        "\n",
        "    li6_retained = np.sum((predicted_labels[li6_mask] == 0)) / np.sum(li6_mask)\n",
        "    po_mislabeled = np.sum((predicted_labels[po_mask] == 0)) / np.sum(po_mask)\n",
        "\n",
        "    print(f\"{name} => Li6 retained: {li6_retained*100:.2f}% | \"\n",
        "          f\"Po contamination: {po_mislabeled*100:.2f}%\")\n",
        "    print(\"-\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Classify the Phys Dataset\n",
        "\n",
        "Finally, we apply the trained models to an unlabeled **Phys** dataset. Using the threshold found above (which ensures ≤5% Po contamination), we assign each signal to Li6 or Po. We then estimate how many signals are Li6 vs. Po."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "phys_waveforms = load_waveforms(\n",
        "    file_path=\"data/Phys.npz\",\n",
        "    fraction=1,         \n",
        "    time_start=0,\n",
        "    time_end=7756\n",
        ")\n",
        "print(\"Phys dataset shape:\", phys_waveforms.shape)\n",
        "\n",
        "for model, name in models:\n",
        "    best_thresh = thresholds[name]\n",
        "    predicted_labels_phys = classify_dataset(\n",
        "        model=model,\n",
        "        waveforms=phys_waveforms,\n",
        "        device=device,\n",
        "        threshold=best_thresh\n",
        "    )\n",
        "\n",
        "    li6_count = np.sum(predicted_labels_phys == 0)\n",
        "    po_count  = np.sum(predicted_labels_phys == 1)\n",
        "    total     = len(predicted_labels_phys)\n",
        "\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    print(f\"Threshold used: {best_thresh:.3f}\")\n",
        "    print(f\"Estimated Li6 in Phys: {li6_count} ({li6_count/total*100:.2f}%)\")\n",
        "    print(f\"Estimated Po  in Phys: {po_count}  ({po_count/total*100:.2f}%)\")\n",
        "    print(\"-\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Another Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "During our testing, we noticed that most Po had signal after 4000 while almost none Si. From this simple idea, we developped a 10 lines script that has a similar accuracy to our best CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(52238, 4, 7756)\n",
            "(53000, 4, 7756)\n",
            "(24000, 4, 7756)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 23\u001b[0m\n\u001b[0;32m     18\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6000\u001b[39m  \u001b[38;5;66;03m# Define the threshold\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signal \u001b[38;5;129;01min\u001b[39;00m Pow:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Count the number of channels with non-zero values after the threshold\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     valid_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([np\u001b[38;5;241m.\u001b[39many(signal[channel][threshold:] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m)])\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_channels \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     25\u001b[0m         count_Po \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "Cell \u001b[1;32mIn[5], line 23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6000\u001b[39m  \u001b[38;5;66;03m# Define the threshold\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signal \u001b[38;5;129;01min\u001b[39;00m Pow:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Count the number of channels with non-zero values after the threshold\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     valid_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m)])\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_channels \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     25\u001b[0m         count_Po \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\André\\Desktop\\MASTER\\final_project\\Project_Master_NAC\\venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:2472\u001b[0m, in \u001b[0;36m_any_dispatcher\u001b[1;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[0;32m   2464\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m   2466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(\n\u001b[0;32m   2467\u001b[0m         a, np\u001b[38;5;241m.\u001b[39madd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, dtype, out,\n\u001b[0;32m   2468\u001b[0m         keepdims\u001b[38;5;241m=\u001b[39mkeepdims, initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere\n\u001b[0;32m   2469\u001b[0m     )\n\u001b[1;32m-> 2472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_any_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2473\u001b[0m                     where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, where, out)\n\u001b[0;32m   2477\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_any_dispatcher)\n\u001b[0;32m   2478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21many\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Po = np.load(\"data/Po.npz\")\n",
        "Pow= Po['data_array']\n",
        "print(Pow.shape)\n",
        "\n",
        "Li6 = np.load(\"data/Li6.npz\")\n",
        "Liw= Li6['data_array']\n",
        "print(Liw.shape)\n",
        "\n",
        "\n",
        "Phys = np.load(\"data/Phys.npz\")\n",
        "Physw= Phys['data_array']\n",
        "print(Physw.shape)\n",
        "\n",
        "\n",
        "# Initialization of counters for Po and Li\n",
        "count_Po = 0\n",
        "count_Li = 0\n",
        "threshold = 6000  # Define the threshold\n",
        "\n",
        "\n",
        "for signal in Pow:\n",
        "    # Count the number of channels with non-zero values after the threshold\n",
        "    valid_channels = sum([np.any(signal[channel][threshold:] != 0) for channel in range(4)])\n",
        "    if valid_channels >= 2:\n",
        "        count_Po += 1\n",
        "\n",
        "for signal in Liw:\n",
        "    valid_channels = sum([np.any(signal[channel][threshold:] != 0) for channel in range(4)])\n",
        "    if valid_channels >= 2:\n",
        "        count_Li += 1\n",
        "\n",
        "# Total of Po and Li events\n",
        "nb_Po = Pow.shape[0]\n",
        "nb_Li = Liw.shape[0]\n",
        "\n",
        "# Calculate percentages of valid and invalid signals\n",
        "nb_Po_OK = count_Po / nb_Po\n",
        "nb_Po_notOK = 1 - nb_Po_OK\n",
        "nb_Li_notOK = count_Li / nb_Li\n",
        "nb_Li_OK = 1 - nb_Li_notOK\n",
        "\n",
        "print(f\"Percentage of valid Po signals: {nb_Po_OK * 100:.2f}%\")\n",
        "print(f\"Percentage of invalid Po signals: {nb_Po_notOK * 100:.2f}%\")\n",
        "print(f\"Percentage of valid Li signals: {nb_Li_OK * 100:.2f}%\")\n",
        "print(f\"Percentage of invalid Li signals: {nb_Li_notOK * 100:.2f}%\")\n",
        "\n",
        "\n",
        "# Create the confusion matrix\n",
        "conf_mat = np.array([[count_Po, nb_Po - count_Po], \n",
        "                     [count_Li, nb_Li- count_Li]])\n",
        "conf_mat = conf_mat.astype(int)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Po', 'Li'], yticklabels=['Po', 'Li'])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can recount the number of Si"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count_Phys = 0\n",
        "# Iterate over the Phys signals\n",
        "for signal in Physw:\n",
        "    # Count the number of channels with non-zero values after the threshold\n",
        "    valid_channels = sum([np.any(signal[channel][threshold:] != 0) for channel in range(4)])\n",
        "    # Increment the counter if at least 2 channels meet the criterion\n",
        "    if valid_channels >= 2:\n",
        "        count_Phys += 1\n",
        "\n",
        "print(f\"Number of Po in Phys: {count_Phys}\")\n",
        "print(f\"Number of Li in Phys: {Physw.shape[0] - count_Phys}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As seen above, the results obtained using this method are extremely encouraging: less than 5% false positives for both Li and Po. This provides essential insights for developing a machine learning-based solution: all signals are useful for discriminating between Li and Po, not just the portion containing the main pulse. Furthermore, it would be interesting to explore a multi-branch method that considers all four signals simultaneously, rather than treating them as four independent signals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialization of counters for Po and Li\n",
        "thresholds = np.linspace(2000, 7000, 10, dtype=int)  # Thresholds ranging from 4000 to 7000 with 10 points\n",
        "Po_percentages = []\n",
        "Li_percentages = []\n",
        "\n",
        "# Iterate over different thresholds\n",
        "for threshold in thresholds:\n",
        "    count_Po = 0\n",
        "    count_Li = 0\n",
        "    \n",
        "    # Count valid signals for Po\n",
        "    for signal in Pow:\n",
        "        valid_channels = sum([np.any(signal[channel][threshold:] != 0) for channel in range(4)])\n",
        "        if valid_channels >= 2:\n",
        "            count_Po += 1\n",
        "\n",
        "    # Count valid signals for Li\n",
        "    for signal in Liw:\n",
        "        valid_channels = sum([np.any(signal[channel][threshold:] != 0) for channel in range(4)])\n",
        "        if valid_channels >= 2:\n",
        "            count_Li += 1\n",
        "\n",
        "    # Total of Po and Li events\n",
        "    nb_Po = Pow.shape[0]\n",
        "    nb_Li = Liw.shape[0]\n",
        "\n",
        "    # Calculate percentages of valid signals for this threshold\n",
        "    nb_Po_OK = count_Po / nb_Po\n",
        "    nb_Li_notOK = count_Li / nb_Li\n",
        "    nb_Li_OK = 1 - nb_Li_notOK\n",
        "\n",
        "\n",
        "    # Store the percentages\n",
        "    Po_percentages.append(nb_Po_OK * 100)\n",
        "    Li_percentages.append(nb_Li_OK * 100)\n",
        "\n",
        "# Plot Percentages against thresholds\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(thresholds, Po_percentages, marker='o', label=\"Po Percentages\")\n",
        "plt.plot(thresholds, Li_percentages, marker='o', label=\"Li Percentages\")\n",
        "plt.title(\"Percentages of Valid Signals vs Thresholds\")\n",
        "plt.xlabel(\"Thresholds\")\n",
        "plt.ylabel(\"Percentage (%)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Tasks Answers\n",
        "\n",
        "Below is a concise summary of how the **above code** addresses the five requested tasks:\n",
        "\n",
        "---\n",
        "**1. Explore the datasets & qualitative differences**  \n",
        "- *Qualitative method*:  \n",
        "  We plotted **random waveforms** and **average waveforms** for Li6 vs Po, then compared distributions of **mean** and **max** amplitude. Histograms and difference plots highlight key discrepancies (e.g., Li6 sometimes exhibits a lower amplitude in certain channels).  \n",
        "- *Chosen input format*:  \n",
        "  Our data shape is `(N, 4, T)`, with 4 channels and T timepoints. This format allows direct input to CNNs and simpler 1D or 2D transformations.  \n",
        "- *PyTorch Dataset & splits*:  \n",
        "  We defined `ScintillationDataset` (in `utils.deep_learning`) to yield `(waveform, label)` pairs. A standard 80/20 split is used for training/test.  \n",
        "\n",
        "---\n",
        "**2. Build a classifier model & aim >80% accuracy**  \n",
        "- We tested several models (RandomForest, SVM, XGBoost) using *feature engineering* (Mean, Peak, etc.) and later advanced **CNN** models (single-branch, multi-branch, attention).  \n",
        "- *Training metrics*: We log the **loss** and **accuracy** per epoch in the deep-learning approach, and confusion matrices for the simpler ML models.  \n",
        "- *Stopping rationale*: We ran a fixed 10-epoch training for CNNs, acknowledging that in practice, we might use early stopping if the validation loss plateaus or deteriorates.  \n",
        "\n",
        "---\n",
        "**3. Estimate epistemic uncertainty**  \n",
        "- *Method chosen*: **Monte Carlo Dropout**. It is straightforward to implement, requires multiple forward passes at inference, and yields a distribution of predicted probabilities.  \n",
        "\n",
        "---\n",
        "**4. Limit Po contamination to 5%**  \n",
        "- Using the model’s Li6 probability `p(Li6)`, we scanned for a *threshold* such that only 5% of Po signals exceed it (i.e., are misidentified as Li6). This ensures contamination is capped at 5%.  \n",
        "- We then observed how many Li6 events are *retained* at that threshold.  \n",
        "\n",
        "---\n",
        "**5. Classify Phys**  \n",
        "- With the threshold set to meet the contamination requirement, we predicted Li6 vs Po for the **Phys** dataset. We reported the counts (and percentages) of each.  \n",
        "\n",
        "---\n",
        "\n",
        "*End of Notebook*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
